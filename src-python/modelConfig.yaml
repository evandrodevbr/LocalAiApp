models:
  lfm_2.5_1.2b:
    repo_id: "LiquidAI/LFM2.5-1.2B-Instruct-GGUF"
    filename: "LFM2.5-1.2B-Instruct-Q6_K.gguf"
    context_window: 2048
    temperature: 0.1
    max_tokens: 512
    type: "llama-cpp"

# Exemplo de futura expans√£o
# phi3_mini:
#   repo_id: "microsoft/Phi-3-mini-4k-instruct-gguf"
#   filename: "Phi-3-mini-4k-instruct-q4.gguf"
#   type: "llama-cpp"